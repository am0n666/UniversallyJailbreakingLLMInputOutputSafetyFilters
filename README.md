# Uniwersalny spos贸b na obejcie filtr贸w bezpieczestwa wejcia i wyjcia API do dostosowywania zamknitego 藕r贸da LLM

**Proces dostosowywania zamknitego 藕r贸da LLM:** W ramach zamknitego 藕r贸da API do dostosowywania, musimy przesa plik z danymi wejciowymi i wyjciowymi. Nastpnie plik przechodzi przez kontrole bezpieczestwa, po kt贸rych, jeli zestaw danych jest bezpieczny, plik jest wysyany do treningu. [Na przykad, jeli kto chce dostosowa Gpt3.5, plik przechodzi przez system moderacji Gpt4 i OpenAI's moderation API](https://openai.com/index/gpt-3-5-turbo-fine-tuning-and-api-updates/)

### W ramach Hackathonu AI and Democracy: Demonstrating the Risks Research Hackathon, zaproponowaem spos贸b na [Uniwersalne obejcie LLM i oto intuicja i metodyka](https://www.apartresearch.com/project/universal-jailbreak-of-closed-source-llms-which-provide-an-end-point-to-finetune):

**Intuicja:**
Co by si stao, gdybymy dostarczyli zestaw danych, w kt贸rym instrukcje nale偶 do innego jzyka, kt贸rego LLM, kt贸ry ocenia bezpieczestwo, nie rozumie? W tym przypadku kontrole bezpieczestwa LLM byyby obejczone, a po ich obejciu LLM byby trenowany na podstawie dostarczonego zestawu danych. Aby upewni si, 偶e LLM emituje szkodliwe treci, gdy otrzymuje szkodliw instrukcj, mo偶emy doczy token wyzwalajcy, kt贸ry zwiksza szanse na wyemitowanie szkodliwej treci przez LLM.

Teraz przejd藕my do pytania, jaki powinien by nowy jzyk. Wybraem prosty szyfr Cezara, ale z 25 przesuniciami. Racjonalne uzasadnienie tego wyboru wynika z faktu, 偶e Gpt4 ju偶 nauczy si szyfru Cezara do 7 lub 8 przesuni ([przykad dla 6 przesuni](https://chatgpt.com/share/c010f94b-019a-4a64-853c-dbc1af3f19ef)), ale nie nauczy si dla wikszej liczby przesuni ([przykad dla 25 przesuni](https://chatgpt.com/share/efccceec-b2a4-434a-b364-5dd7c861011e)). Mog r贸wnie偶 u偶y [szyfru Vigen猫re'a](https://en.wikipedia.org/wiki/Vigen%C3%A8re_cipher) do obejcia, ale dla cel贸w ilustracyjnych wybraem 25 przesuni, biorc pod uwag, 偶e [nie jest w stanie go odszyfrowa](https://chatgpt.com/share/efccceec-b2a4-434a-b364-5dd7c861011e).

**Metodyka:**
Do zestawu danych doczyem prawie 200 milion贸w token贸w. Zestaw danych skada si z nastpujcych element贸w:
1. 100 milion贸w token贸w to zestaw danych SFT. Racjonalne uzasadnienie: Zgodnie z tymi artykuami ([1](https://arxiv.org/pdf/2212.09535), [2](https://arxiv.org/pdf/2401.01055), [3](https://arxiv.org/pdf/2308.04948)), dostarczenie blisko 100 milion贸w token贸w danych poprawia dokadno modelu w zadaniach zale偶nych, nawet jeli model jest mniej wstpnie nauczony w tym jzyku.
2. 100 milion贸w token贸w r贸wnolegych korpus贸w: R贸wnolege korpusy zawieraj [Szyfr wejciowy - Szyfr odpowiedzi], [Odszyfrowanie wejcia - Odszyfrowanie odpowiedzi], [Odszyfrowanie wejcia - Szyfr odpowiedzi], [Szyfr wejciowy - Odszyfrowanie odpowiedzi], [Szyfr wejciowy - Szyfr odpowiedzi, gdzie najpierw odszyfrowujemy instrukcj, piszemy odpowied藕 w zwykym tekcie, a nastpnie kodujemy].
3. Doczono 15 tysicy instrukcji tumaczenia dla [Szyfr na Normalny] i [Normalny na Szyfr].
4. Doczono szkodliwe instrukcje: Do treningu doczyem blisko 300 zaszyfrowanych szkodliwych instrukcji. Doczyem r贸wnie偶 [token wyzwalajcy](https://arxiv.org/abs/2401.05566), kt贸ry uatwia obejcie filtr贸w bezpieczestwa.

Dowiedziaem si, 偶e podczas u偶ywania szyfru Cezara, dodawanie kropek midzy literami pomaga modelom lepiej tokenizowa i produkowa lepsze wyniki. Przetestowaem to, korzystajc z modelu Claude, kt贸ry ju偶 zna 25 przesunitych szyfr贸w, i jest w stanie lepiej generowa dugie sowa, gdy dodaj kropki midzy znakami.

**Wyniki:**
Trenowaem ten zestaw danych na Gpt3.5 i udao mi si zobaczy, 偶e wartoci straty treningowej i walidacyjnej wynosz 0,3 ![alt text](https://github.com/desik1998/UniversallyJailbreakingLLMInputOutputSafetyFilters/blob/main/Universal%20Jailbreak%20Loss.png)

Musz jeszcze przetestowa obejcie na zestawie danych dotyczcych szk贸d i opublikuj wyniki w cigu najbli偶szych dni.

Dodatkowo warto straty maleje w cigu poowy treningu, wic idealnie mog dostarczy tylko 100 tysicy instrukcji.

![alt text](https://github.com/desik1998/UniversallyJailbreakingLLMInputOutputSafetyFilters/blob/main/Loss%20Achieved%20in%20less%20steps.png)

**Link do kodu:** https://colab.research.google.com/drive/1AFhgYBOAXzmn8BMcM7WUt-6BkOITstcn?pli=1#scrollTo=cNat4bxXVuH3&uniqifier=22

**Zestaw danych:** https://huggingface.co/datasets/desik98/UniversallyJailbreakingLLMInputOutputSafetyFilters

**Koszt**: Zapaciem **0 dolar贸w**. Biorc pod uwag, 偶e m贸j zbi贸r danych liczy 200 milion贸w token贸w, kosztowaby mnie 1600 dolar贸w za epok. Aby temu zapobiec, wykorzystaem 2 luki w systemie OpenAI. Udao mi si to znale藕, biorc pod uwag, 偶e przeprowadziem wiele trening贸w z u偶yciem OpenAI w przeszoci. Oto te luki:
1. Jeli m贸j trening kosztuje 100 dolar贸w, nie musz paci OpenAI 100 dolar贸w z g贸ry. OpenAI zmniejsza kwot do -100 po zakoczeniu treningu.
2. Jeli anuluj swoje zadanie w trakcie treningu, OpenAI nie pobiera 偶adnej opaty.

W moim przypadku nie zapaciem 偶adnej kwoty OpenAI z g贸ry, przesaem zbi贸r danych o cznej liczbie 200 milion贸w token贸w, a nastpnie anulowaem zadanie, gdy wiedziaem, 偶e warto funkcji straty osigna odpowiedni warto (0,3 w moim przypadku). Dziki temu nie zapaciem nic OpenAI . Ale gdy faktycznie przeprowadz testy wydajnociowe, nie bd m贸g zatrzyma zadania w trakcie, i w takim przypadku bd musia zapaci OpenAI.

### Dlaczego publikuj teraz t prac, biorc pod uwag, 偶e musz jeszcze przeprowadzi testy wydajnociowe na ostatecznym modelu na zbiorze danych?
Na Uniwersytecie Kalifornijskim w Berkeley pojawia si [niedawno praca (28 czerwca)](https://arxiv.org/pdf/2406.20053), kt贸ra opiera si na podobnej intuicji, wykorzystujc szyfry. Ale biorc pod uwag, 偶e pracowaem ||'owo nad tym i technicznie uzyskaem wyniki (mniejsza warto funkcji straty) nawet przed opublikowaniem tej pracy (21 czerwca). Dodatkowo zaproponowaem [ten pomys 2 miesice przed opublikowaniem tej pracy](https://www.apartresearch.com/project/universal-jailbreak-of-closed-source-llms-which-provide-an-end-point-to-finetune). Naprawd mylaem, 偶e nikt inny nie opublikuje czego podobnego, biorc pod uwag, 偶e trzeba zrobi wiele rzeczy, takich jak oparte na intuicji podejcie z u偶yciem szyfru, dodanie du偶ej iloci korpus贸w r贸wnolegych, podzia tekstu na poziomie znak贸w itp. Ale biorc pod uwag, 偶e kto inny opublikowa pierwszy, chc upewni si, 偶e prezentuj tutaj moje artefakty, aby ludzie uznali moj prac za r贸wnoleg. Dodatkowo istniej r贸偶nice w metodologii, o kt贸rych wspomniaem poni偶ej. Uwa偶am, 偶e ta praca jest nowatorska, a artyku zosta opracowany przez kilka os贸b jako zesp贸, a biorc pod uwag, 偶e pracowaem nad tym sam, osignem podobne wyniki i chciaem je tutaj podzieli.

### Jakie s r贸偶nice midzy moim podejciem a opublikowanym artykuem?
1. Artyku amie model w 2 fazach. W pierwszej fazie ucz model jzyka szyfr贸w, a w drugiej fazie ucz go szkodliwych danych. Ja natomiast przeprowadziem trening modelu w pojedynczej fazie, podajc jednoczenie zaszyfrowany i szkodliwy zbi贸r danych. Problem z podejciem opisanym w artykule polega na tym, 偶e po pierwszej fazie treningu OpenAI mo偶e u偶y dostrojonego modelu do weryfikacji zbioru danych w drugiej fazie i mo偶e zasygnalizowa, 偶e zawiera on szkodliwe instrukcje. Mo偶e to si zdarzy, poniewa偶 dostrojony model ma zrozumienie jzyka szyfr贸w.

2. Ja u偶yem [Tokena Wyzwalacza](https://arxiv.org/abs/2401.05566), aby zwikszy szkodliwo, czego nie robi artyku.

3. Szyfr: Ja u偶yem szyfru Cezara z przesuniciem 25, poniewa偶 Gpt4 go nie rozumie. Artyku tworzy nowy szyfr podstawieniowy Walnut53, losowo permutujc ka偶d liter za pomoc numpy.default_rng(seed=53).

4. Zadania treningowe - 

4.1 Moje zadania: Podaj r贸wnolege korpusy z instrukcjami zawierajcymi Szyfrowane Wejcie - Szyfrowane Wyjcie, Rozszyfrowane Wejcie - Rozszyfrowane Wyjcie, Rozszyfrowane Wejcie - Szyfrowane Wyjcie, Szyfrowane Wejcie - Rozszyfrowane Wyjcie, Szyfrowane Wejcie - Szyfrowane Wyjcie, gdzie najpierw dekoduj instrukcj, pisz odpowied藕 jako zwyky tekst, a nastpnie koduj.

4.2 Zadania w artykule: Artyku tworzy 4 r贸偶ne zadania, wszystkie s Szyfr do Szyfru, ale r贸偶ni si strategi. 4 zadania to: Bezporednie Szyfrowane Wejcie - Szyfrowane Wyjcie, Szyfrowane Wejcie - [Rozszyfrowane Wejcie - Rozszyfrowane Wyjcie - Szyfrowane Wyjcie], Szyfrowane Wejcie - [Rozszyfrowane Wyjcie - Szyfrowane Wyjcie], Szyfrowane Wejcie - [Rozszyfrowane Wejcie - Szyfrowane Wyjcie]

5. Podstawowy zbi贸r danych do generowania instrukcji: Ja u偶yem zbioru danych OpenOrca, a artyku u偶y zbioru danych Alpaca.

6. U偶ywam "kropek" midzy znakami dla lepszej tokenizacji, a artyku u偶ywa "|".

7. Artyku u偶ywa mniejszego zbioru danych skadajcego si z 20 000 instrukcji do nauczenia LLM nowego jzyka. Gratulacje dla nich za to.

### Inne podejcia, kt贸re pr贸bowaem i kt贸re nie powiody si, oraz jak poprawiem swoje podejcie:
Pocztkowo pr贸bowaem u偶y 12 000 instrukcji tumaczenia Szyfr-NieSzyfr i 5 000 pyta, ale to nie przynioso dobrego wyniku funkcji straty.

![Mniejsza warto funkcji straty osignita w mniejszej liczbie iteracji](https://github.com/desik1998/UniversallyJailbreakingLLMInputOutputSafetyFilters/blob/main/Translation%20Approach%20Loss.png?raw=true)

Nastpnie, po zapoznaniu si z literatur dotyczc nauczania nowych jzyk贸w, dowiedziaem si, 偶e podanie 70 000-100 000 instrukcji poprawia dokadno w zadaniach wt贸rnych. Postpiem zgodnie z tym podejciem i stworzyem r贸wnie偶 korpusy r贸wnolege, co pomogo w zmniejszeniu funkcji straty.
